{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd8a3ab-ed9a-45d7-96ee-a277c40f9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to create dataset first.\n",
    "## Let's create dataset for both test data and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0fa7a4-8eed-40db-8989-fca2a37a41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For this project I decided to only have melspectrogram data for Stage I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9098051-57d3-4fa0-946e-830ced05e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To build test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0ce0d4-a1ad-49d2-9521-e0b24ecda75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##ALL THE IMPORTS\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9303d02-7afd-4366-8348-475194cb562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The output.csv file contain the path to all the audio files which we will use to iterate\n",
    "df = pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145b6496-81f4-49f7-b50e-599f03b3a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The different genre of the class we have\n",
    "\n",
    "# CLASS_ORDER = ['pop','metal','disco','blues','reggae','classical','rock','hiphop','country','jazz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2ecc86-6903-40eb-b4cb-edec9cac8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = CLASS_ORDER\n",
    "# paths_per_folder = [[] for _ in folder]\n",
    "\n",
    "# for f, grp in df.groupby(\"folder\"):\n",
    "#     if f in folder:\n",
    "#         i = folder.index(f)\n",
    "#         paths_per_folder[i] = grp[\"full_path\"].dropna().tolist()\n",
    "\n",
    "# ## Took all the paths from the output.csv and put them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5abfe06-0386-4eeb-9fd2-67675993b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_list_of_paths(paths, sr=22050, mono=True, seconds=30.0, trim_db=40):\n",
    "#     \"\"\"Return [(y, sr), ...] with each y pad/truncated to the same length.\"\"\"\n",
    "#     target = int(sr * seconds)\n",
    "#     out = []\n",
    "#     for p in paths:\n",
    "#         y, sr_loaded = librosa.load(p, sr=sr, mono=mono)\n",
    "#         if trim_db is not None:\n",
    "#             y, _ = librosa.effects.trim(y, top_db=trim_db)\n",
    "#             # pad / truncate to fixed length\n",
    "#         if len(y) < target:\n",
    "#             y = np.pad(y, (0, target - len(y)))\n",
    "#         else:\n",
    "#             y = y[:target]\n",
    "#             out.append((y, sr))      # <-- tuple per file\n",
    "#     return out\n",
    "\n",
    "# pop, metal, disco, blues, reggae, classical, rock, hiphop, country, jazz = [\n",
    "#     load_list_of_paths(paths, sr=22050, mono=True, seconds=30.0)\n",
    "#     for paths in paths_per_folder\n",
    "# ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd2070c7-ece7-4e5f-9c8b-ded108663772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_melspectogram_by_genre(signals_by_genre, **kwargs):\n",
    "#     \"\"\"\n",
    "#     signals_by_genre: dict like {'pop': [(y, sr), (y, sr), ...], 'metal': [...], ...}\n",
    "#     returns: dict like {'pop': [mfcc_array, ...], 'metal': [mfcc_array, ...], ...}\n",
    "#     \"\"\"\n",
    "#     return {\n",
    "#         genre: [librosa.feature.melspectrogram(\n",
    "#             y=y,\n",
    "#             sr=22050,        # fixed resample rate\n",
    "#             n_fft=2048,      # freq resolution\n",
    "#             hop_length=512,  # time resolution\n",
    "#             win_length=2048, # keep = n_fft for consistency\n",
    "#             window=\"hann\",   # fixed window type\n",
    "#             center=True,\n",
    "#             pad_mode=\"constant\",\n",
    "#             power=2.0,\n",
    "#             n_mels=128,      # fixed mel bands (height)\n",
    "#             fmin=0.0,\n",
    "#             fmax=8000.0,     # IMPORTANT: keep fixed across all songs\n",
    "#             htk=False,\n",
    "#             norm=\"slaney\"\n",
    "#             )\n",
    "#                 for (y, sr_i) in pairs]\n",
    "#         for genre, pairs in signals_by_genre.items()\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94865145-3593-41cc-ae76-2d0f54c56433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_by_genre = {\n",
    "#     \"pop\": pop, \"metal\": metal, \"disco\": disco, \"blues\": blues, \"reggae\": reggae,\n",
    "#     \"classical\": classical, \"rock\": rock, \"hiphop\": hiphop, \"country\": country, \"jazz\": jazz\n",
    "# }\n",
    "# melspectogram = compute_melspectogram_by_genre(signals_by_genre) ## Computer melspectogram for all the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77b61376-2a8e-47b7-b982-d42ce497c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal, sr = librosa.load(\"data/train/blues/blues.00000.au\", sr= 22050, mono = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0a774b-ff98-45b0-9344-8192b05b4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melspectrogram = librosa.feature.melspectrogram(\n",
    "#             y=signal,\n",
    "#             sr=22050,        # fixed resample rate\n",
    "#             n_fft=2048,      # freq resolution\n",
    "#             hop_length=512,  # time resolution\n",
    "#             win_length=2048, # keep = n_fft for consistency\n",
    "#             window=\"hann\",   # fixed window type\n",
    "#             center=True,\n",
    "#             pad_mode=\"constant\",\n",
    "#             power=2.0,\n",
    "#             n_mels=128,      # fixed mel bands (height)\n",
    "#             fmin=0.0,\n",
    "#             fmax=8000.0,     # IMPORTANT: keep fixed across all songs\n",
    "#             htk=False,\n",
    "#             norm=\"slaney\"\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b2ef4e-9a6e-4d5b-a56b-9be14c5dac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1293)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melspectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9af0a80-a415-4b7a-90c3-860c2bd7ca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.8268799e-01, 8.9119792e-01, 5.1211077e-01, ..., 1.5947603e+00,\n",
       "        2.1680443e+00, 1.6678190e+01],\n",
       "       [2.2305069e+00, 4.1655021e+00, 4.5266399e+00, ..., 8.1707211e+00,\n",
       "        1.7254709e+01, 3.7458706e+01],\n",
       "       [6.9113249e-01, 7.1795809e-01, 3.5434721e+00, ..., 4.6220841e+00,\n",
       "        3.3292946e+01, 3.1175535e+01],\n",
       "       ...,\n",
       "       [5.3926464e-04, 1.2663329e-03, 2.6247166e-03, ..., 1.3400511e-03,\n",
       "        2.3673696e-03, 2.6777522e-03],\n",
       "       [1.9684255e-04, 5.8042654e-04, 1.8922262e-03, ..., 4.2267016e-04,\n",
       "        1.3099413e-03, 2.0431615e-03],\n",
       "       [9.1946844e-05, 3.8242034e-04, 1.6103965e-03, ..., 4.0689029e-04,\n",
       "        1.4513478e-03, 1.4910798e-03]], shape=(128, 1293), dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c2b5b6d-2317-4d27-acec-27c0a8ca7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = ['pop','metal','disco','blues','reggae',\n",
    "          'classical','rock','hiphop','country','jazz']\n",
    "\n",
    "genre_to_idx = {g:i for i,g in enumerate(GENRES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c771ed7-9fc1-4f1a-804c-047056526d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fixed_audio(path, sr=22050, seconds=30, trim_db = 40):\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    target = sr * seconds\n",
    "    y, _ = librosa.effects.trim(y, top_db=trim_db)\n",
    "    \n",
    "    if len(y) < target:\n",
    "        y = np.pad(y, (0, target-len(y)))\n",
    "    else:\n",
    "        y = y[:target]\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddbba43a-b7db-433b-97c2-4e119605bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logmel(y, sr):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr,\n",
    "        n_fft=2048,\n",
    "        hop_length=512,\n",
    "        win_length=2048,\n",
    "        window=\"hann\",\n",
    "        center=True,\n",
    "        pad_mode=\"constant\",\n",
    "        power=2.0,\n",
    "        n_mels=128,\n",
    "        fmin=0.0,\n",
    "        fmax=8000.0,\n",
    "        htk=False,\n",
    "        norm=\"slaney\"\n",
    "    )\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "    return logmel  # (128, 1293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4983c47-d9f8-4d9e-9143-e12c46e79905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    path  = row[\"full_path\"]\n",
    "    genre = row[\"folder\"]     \n",
    "    \n",
    "    # 1) audio\n",
    "    y, sr = load_fixed_audio(path)\n",
    "\n",
    "    # 2) spectrogram\n",
    "    spec = get_logmel(y, sr)   # (128,1293)\n",
    "\n",
    "    X_list.append(spec)\n",
    "    y_list.append(genre_to_idx[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17d9e486-a9e6-4e11-97c7-dab83c79533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900\n",
      "(128, 1292)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_list), len(y_list))\n",
    "print(X_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29a9cb4a-8a76-4833-a030-7b34246b3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 128, 1292) (900,)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(X_list)   # (900, 128, 1293)\n",
    "y = np.array(y_list)   # (900,)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95fb6e17-fe67-4880-84b0-e7be1363e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 128, 1292)\n",
      "(900, 1, 128, 1292)\n"
     ]
    }
   ],
   "source": [
    "X_norm = (X - X.mean(axis=(1,2), keepdims=True)) / (X.std(axis=(1,2), keepdims=True) + 1e-8)\n",
    "print(X_norm.shape)   # (900, 128, 1292)\n",
    "\n",
    "# then add channel\n",
    "X_norm = X_norm[:, np.newaxis, :, :]\n",
    "print(X_norm.shape)   # (900, 1, 128, 1292)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43e9f082-0365-4c3a-8445-6f33de2a04e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (720, 1, 128, 1292)\n",
      "X_val  : (180, 1, 128, 1292)\n",
      "y_train: (720,)\n",
      "y_val  : (180,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_norm, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val  :\", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_val  :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d145be5-f041-46a3-b284-37aed05cfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating models and layers here\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f4a38-1c4a-4817-af79-216f3a54aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(900,128,1292)\n",
    "CNNmodel = models.Sequential()\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Dropout(0.2))\n",
    "CNNmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Dropout(0.2))\n",
    "CNNmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.Flatten())\n",
    "CNNmodel.add(layers.Dense(64, activation='relu'))\n",
    "CNNmodel.add(layers.Dropout(0.2))\n",
    "CNNmodel.add(layers.Dense(32, activation='relu'))\n",
    "CNNmodel.add(layers.Dense(24, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a7fb9-9990-49f9-a15a-667e348bf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.compile(optimizer='adam',loss=tf.keras.losses.SparseCategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83beee2-5621-4d1b-a31c-2f4b2d04f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = CNNmodel.fit(X_train, y_train, epochs=20, validation_data= (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecc4b0-9498-401b-8dd9-32b0fb011fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
